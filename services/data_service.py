"""Data processing and validation business service."""

import pandas as pd
from typing import Dict, List, Any, Tuple
from datetime import datetime
import re
from loguru import logger


class DataValidationError(Exception):
    """Custom exception for data validation errors."""
    pass


class DataProcessingError(Exception):
    """Custom exception for data processing errors."""
    pass


class DataService:
    """Handles data import, validation, and processing."""

    REQUIRED_TIMESHEET_COLUMNS = [
        'Employee Name', 'Regular Hours', 'OT Hours', 'DT Hours'
    ]

    REQUIRED_REVENUE_COLUMNS = [
        'Business Unit', 'Jobs total revenue'
    ]

    OPTIONAL_REVENUE_COLUMNS = [
        'Lead Generated By', 'Sold By', 'Assigned Technicians'
    ]

    def __init__(self):
        self.timesheet_data = None
        self.revenue_data = None
        self.validation_errors = []
        self.data_quality_score = 0

    def validate_timesheet_data(self, df: pd.DataFrame) -> Tuple[bool, List[str], pd.DataFrame]:
        """Validate timesheet data format and content.

        Args:
            df: DataFrame containing timesheet data

        Returns:
            Tuple of (is_valid, errors, cleaned_dataframe)
        """
        errors = []
        cleaned_df = df.copy()

        try:
            # Check required columns
            missing_cols = [col for col in self.REQUIRED_TIMESHEET_COLUMNS
                          if col not in df.columns]
            if missing_cols:
                errors.append(f"Missing required columns: {', '.join(missing_cols)}")
                return False, errors, pd.DataFrame()

            # Check for empty DataFrame
            if df.empty:
                errors.append("Timesheet data is empty")
                return False, errors, pd.DataFrame()

            # Validate employee names
            if cleaned_df['Employee Name'].isnull().any():
                errors.append("Some employee names are missing")
                cleaned_df = cleaned_df.dropna(subset=['Employee Name'])

            # Remove empty employee names
            cleaned_df = cleaned_df[cleaned_df['Employee Name'].str.strip() != '']

            # Validate and clean numeric columns
            numeric_columns = ['Regular Hours', 'OT Hours', 'DT Hours']
            for col in numeric_columns:
                if col in cleaned_df.columns:
                    # Convert to numeric, replacing non-numeric with 0
                    cleaned_df[col] = pd.to_numeric(cleaned_df[col], errors='coerce').fillna(0)

                    # Check for negative values
                    if (cleaned_df[col] < 0).any():
                        errors.append(f"Negative values found in {col} column")
                        cleaned_df[col] = cleaned_df[col].clip(lower=0)

            # Add derived columns
            cleaned_df['Total Hours'] = (
                cleaned_df['Regular Hours'] +
                cleaned_df['OT Hours'] +
                cleaned_df['DT Hours']
            )

            # Check for employees with zero total hours
            zero_hours = cleaned_df[cleaned_df['Total Hours'] == 0]
            if not zero_hours.empty:
                errors.append(f"{len(zero_hours)} employees have zero total hours")

            # Remove duplicates
            initial_count = len(cleaned_df)
            cleaned_df = cleaned_df.drop_duplicates(subset=['Employee Name'])
            if len(cleaned_df) < initial_count:
                errors.append(f"Removed {initial_count - len(cleaned_df)} duplicate employee entries")

            logger.info(f"Timesheet validation: {len(cleaned_df)} valid records, {len(errors)} warnings")
            return len(errors) == 0 or all('warning' in err.lower() for err in errors), errors, cleaned_df

        except Exception as e:
            logger.error(f"Error validating timesheet data: {e}")
            errors.append(f"Validation error: {str(e)}")
            return False, errors, pd.DataFrame()

    def validate_revenue_data(self, df: pd.DataFrame) -> Tuple[bool, List[str], pd.DataFrame]:
        """Validate revenue data format and content.

        Args:
            df: DataFrame containing revenue data

        Returns:
            Tuple of (is_valid, errors, cleaned_dataframe)
        """
        errors = []
        cleaned_df = df.copy()

        try:
            # Check required columns
            missing_cols = [col for col in self.REQUIRED_REVENUE_COLUMNS
                          if col not in df.columns]
            if missing_cols:
                errors.append(f"Missing required columns: {', '.join(missing_cols)}")
                return False, errors, pd.DataFrame()

            # Check for empty DataFrame
            if df.empty:
                errors.append("Revenue data is empty")
                return False, errors, pd.DataFrame()

            # Validate business unit names
            if cleaned_df['Business Unit'].isnull().any():
                errors.append("Some business unit names are missing")
                cleaned_df = cleaned_df.dropna(subset=['Business Unit'])

            # Remove empty business unit names
            cleaned_df = cleaned_df[cleaned_df['Business Unit'].str.strip() != '']

            # Validate and clean revenue column
            revenue_col = 'Jobs total revenue'
            if revenue_col in cleaned_df.columns:
                # Handle string revenue values (remove $ and commas)
                if cleaned_df[revenue_col].dtype == 'object':
                    cleaned_df[revenue_col] = cleaned_df[revenue_col].astype(str)
                    cleaned_df[revenue_col] = cleaned_df[revenue_col].str.replace('$', '', regex=False)
                    cleaned_df[revenue_col] = cleaned_df[revenue_col].str.replace(',', '', regex=False)
                    cleaned_df[revenue_col] = cleaned_df[revenue_col].str.replace(' ', '', regex=False)

                # Convert to numeric
                cleaned_df[revenue_col] = pd.to_numeric(cleaned_df[revenue_col], errors='coerce').fillna(0)

                # Check for negative revenue
                if (cleaned_df[revenue_col] < 0).any():
                    errors.append("Negative revenue values found")
                    cleaned_df[revenue_col] = cleaned_df[revenue_col].clip(lower=0)

                # Check for zero revenue
                zero_revenue = cleaned_df[cleaned_df[revenue_col] == 0]
                if not zero_revenue.empty:
                    errors.append(f"{len(zero_revenue)} business units have zero revenue")

            # Process optional columns
            for col in self.OPTIONAL_REVENUE_COLUMNS:
                if col in cleaned_df.columns:
                    # Handle assigned technicians - split into list
                    if col == 'Assigned Technicians':
                        cleaned_df[col] = cleaned_df[col].fillna('')
                        cleaned_df[col] = cleaned_df[col].astype(str)
                        # Split on common separators and clean
                        cleaned_df['Technician_List'] = cleaned_df[col].apply(
                            lambda x: [name.strip() for name in re.split(r'[,;|&]', x)
                                     if name.strip()] if x else []
                        )
                    else:
                        # Clean employee name fields
                        cleaned_df[col] = cleaned_df[col].fillna('').astype(str).str.strip()

            # Remove duplicates
            initial_count = len(cleaned_df)
            cleaned_df = cleaned_df.drop_duplicates(subset=['Business Unit'])
            if len(cleaned_df) < initial_count:
                errors.append(f"Removed {initial_count - len(cleaned_df)} duplicate business unit entries")

            logger.info(f"Revenue validation: {len(cleaned_df)} valid records, {len(errors)} warnings")
            return len(errors) == 0 or all('warning' in err.lower() for err in errors), errors, cleaned_df

        except Exception as e:
            logger.error(f"Error validating revenue data: {e}")
            errors.append(f"Validation error: {str(e)}")
            return False, errors, pd.DataFrame()

    def calculate_data_quality_score(self, timesheet_df: pd.DataFrame,
                                   revenue_df: pd.DataFrame) -> Dict[str, Any]:
        """Calculate data quality score and metrics.

        Args:
            timesheet_df: Validated timesheet DataFrame
            revenue_df: Validated revenue DataFrame

        Returns:
            Dictionary with quality metrics
        """
        quality_metrics = {
            'overall_score': 0,
            'timesheet_score': 0,
            'revenue_score': 0,
            'issues': [],
            'recommendations': []
        }

        try:
            # Timesheet quality checks
            timesheet_score = 100

            if not timesheet_df.empty:
                # Check for missing data
                missing_hours = timesheet_df[timesheet_df['Total Hours'] == 0]
                if not missing_hours.empty:
                    timesheet_score -= min(20, len(missing_hours) * 2)
                    quality_metrics['issues'].append(f"{len(missing_hours)} employees with zero hours")

                # Check for extreme values
                extreme_hours = timesheet_df[timesheet_df['Total Hours'] > 80]
                if not extreme_hours.empty:
                    timesheet_score -= min(10, len(extreme_hours) * 3)
                    quality_metrics['issues'].append(f"{len(extreme_hours)} employees with >80 hours")

                # Check for reasonable OT ratios
                high_ot = timesheet_df[timesheet_df['OT Hours'] > timesheet_df['Regular Hours']]
                if not high_ot.empty:
                    timesheet_score -= min(5, len(high_ot))
                    quality_metrics['recommendations'].append("Review high overtime ratios")

            # Revenue quality checks
            revenue_score = 100

            if not revenue_df.empty:
                # Check for missing revenue
                zero_revenue = revenue_df[revenue_df['Jobs total revenue'] == 0]
                if not zero_revenue.empty:
                    revenue_score -= min(30, len(zero_revenue) * 5)
                    quality_metrics['issues'].append(f"{len(zero_revenue)} units with zero revenue")

                # Check for missing commission fields
                if 'Lead Generated By' in revenue_df.columns:
                    missing_lead = revenue_df[revenue_df['Lead Generated By'] == '']
                    if not missing_lead.empty:
                        revenue_score -= min(10, len(missing_lead))
                        quality_metrics['recommendations'].append("Consider adding lead generation data")

                if 'Assigned Technicians' in revenue_df.columns:
                    missing_techs = revenue_df[~revenue_df['Technician_List'].apply(bool)]
                    if not missing_techs.empty:
                        revenue_score -= min(15, len(missing_techs) * 2)
                        quality_metrics['recommendations'].append(
                            "Add technician assignments for work done commissions"
                        )

            quality_metrics['timesheet_score'] = max(0, timesheet_score)
            quality_metrics['revenue_score'] = max(0, revenue_score)
            quality_metrics['overall_score'] = (
                quality_metrics['timesheet_score'] + quality_metrics['revenue_score']
            ) / 2

            logger.info(f"Data quality score: {quality_metrics['overall_score']:.1f}%")
            return quality_metrics

        except Exception as e:
            logger.error(f"Error calculating data quality: {e}")
            return {
                'overall_score': 0,
                'timesheet_score': 0,
                'revenue_score': 0,
                'issues': [f"Quality calculation error: {str(e)}"],
                'recommendations': []
            }

    def merge_employee_data(self, timesheet_df: pd.DataFrame,
                          revenue_df: pd.DataFrame) -> List[str]:
        """Identify employees referenced in revenue but missing from timesheet.

        Args:
            timesheet_df: Timesheet DataFrame
            revenue_df: Revenue DataFrame

        Returns:
            List of employee names that need to be added to timesheet
        """
        timesheet_employees = set(timesheet_df['Employee Name'].tolist()) if not timesheet_df.empty else set()
        revenue_employees = set()

        if not revenue_df.empty:
            # Collect all employees referenced in revenue data
            for col in ['Lead Generated By', 'Sold By']:
                if col in revenue_df.columns:
                    revenue_employees.update(revenue_df[col].dropna().tolist())

            # Add technicians from technician lists
            if 'Technician_List' in revenue_df.columns:
                for tech_list in revenue_df['Technician_List']:
                    if tech_list:
                        revenue_employees.update(tech_list)

        # Remove empty strings
        revenue_employees = {emp for emp in revenue_employees if emp and emp.strip()}

        missing_employees = revenue_employees - timesheet_employees

        if missing_employees:
            logger.warning(f"Found {len(missing_employees)} employees in revenue data but not in timesheet")

        return sorted(list(missing_employees))

    def export_data_summary(self, timesheet_df: pd.DataFrame,
                          revenue_df: pd.DataFrame) -> Dict[str, Any]:
        """Create comprehensive data summary for export.

        Args:
            timesheet_df: Timesheet DataFrame
            revenue_df: Revenue DataFrame

        Returns:
            Dictionary with data summary statistics
        """
        summary = {
            'timestamp': datetime.now().isoformat(),
            'timesheet': {
                'total_employees': len(timesheet_df) if not timesheet_df.empty else 0,
                'total_hours': float(timesheet_df['Total Hours'].sum()) if not timesheet_df.empty else 0,
                'total_regular_hours': float(timesheet_df['Regular Hours'].sum()) if not timesheet_df.empty else 0,
                'total_ot_hours': float(timesheet_df['OT Hours'].sum()) if not timesheet_df.empty else 0,
                'total_dt_hours': float(timesheet_df['DT Hours'].sum()) if not timesheet_df.empty else 0
            },
            'revenue': {
                'total_business_units': len(revenue_df) if not revenue_df.empty else 0,
                'total_revenue': float(revenue_df['Jobs total revenue'].sum()) if not revenue_df.empty else 0,
                'avg_revenue_per_unit': float(revenue_df['Jobs total revenue'].mean()) if not revenue_df.empty else 0,
                'units_with_lead_gen': 0,
                'units_with_sales': 0,
                'units_with_techs': 0
            },
            'data_quality': self.calculate_data_quality_score(timesheet_df, revenue_df)
        }

        # Count commission opportunity coverage
        if not revenue_df.empty:
            if 'Lead Generated By' in revenue_df.columns:
                summary['revenue']['units_with_lead_gen'] = len(
                    revenue_df[revenue_df['Lead Generated By'] != '']
                )

            if 'Sold By' in revenue_df.columns:
                summary['revenue']['units_with_sales'] = len(
                    revenue_df[revenue_df['Sold By'] != '']
                )

            if 'Technician_List' in revenue_df.columns:
                summary['revenue']['units_with_techs'] = len(
                    revenue_df[revenue_df['Technician_List'].apply(bool)]
                )

        return summary
